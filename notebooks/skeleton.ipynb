{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã **Project Overview**\n",
    "\n",
    "**Dataset:** MIMIC-III (Medical Information Mart for Intensive Care III)\n",
    "- Contains de-identified health data from ~60,000 ICU admissions\n",
    "- Available through PhysioNet on Google Cloud BigQuery\n",
    "- Requires special access credentials and authentication\n",
    "\n",
    "**Methodology:** \n",
    "- **Temporal Design:** Extract features from first 48 hours, predict outcomes after 6-hour gap\n",
    "- **Patient Selection:** First admission only, minimum 54-hour stay requirement\n",
    "- **Feature Extraction:** Multiple clinical data modalities (demographics, vitals, labs, medications, microbiology)\n",
    "- **Model Requirements:** Calibrated probability outputs for all three targets\n",
    "\n",
    "**Key Constraints:**\n",
    "- No data leakage between temporal windows\n",
    "- Patient-level data splits to prevent information leakage\n",
    "- Clinical interpretability and feature importance analysis required\n",
    "\n",
    "This notebook handles the necessary setup for running the project in both Google Colab and a local environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project prereqs\n",
    "\n",
    "this section is for the prereqs for the project.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# A robust way to check if we are in Google Colab\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    from google.colab import data_table\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configure Google Cloud Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'deep-atlas-413309' # Yair Bigquery Project ID\n",
    "# project_id = 'light-legend-457315-k3' # Lital Bigquery Project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Authenticate and Initialize Client\n",
    "\n",
    "**üîë Authentication Process:**\n",
    "\n",
    "The MIMIC-III dataset requires proper authentication to access. This cell handles two scenarios:\n",
    "\n",
    "**In Google Colab:**\n",
    "- Uses `auth.authenticate_user()` which will prompt you to:\n",
    "  1. Click on the authentication link\n",
    "  2. Sign in with your Google account (must have MIMIC-III access)\n",
    "  3. Copy the authorization code back to the notebook\n",
    "- Enables enhanced dataframe formatting for better visualization\n",
    "\n",
    "**Locally:** \n",
    "- Uses credentials from the Google Cloud SDK\n",
    "- **Required setup:** You must run this command once in your terminal:\n",
    "  ```bash\n",
    "  gcloud auth application-default login\n",
    "  ```\n",
    "- This opens a browser window for one-time authentication setup\n",
    "- Credentials are then stored locally for future use\n",
    "\n",
    "**‚ö†Ô∏è Important Notes:**\n",
    "- Your Google account must have been granted access to the MIMIC-III dataset\n",
    "- Access requires completing the CITI training and signing the data use agreement\n",
    "- If authentication fails, check that you have the correct project permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local Google Cloud SDK credentials.\n",
      "BigQuery client initialized for project: deep-atlas-413309\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    print(\"Authenticating in Google Colab...\")\n",
    "    auth.authenticate_user()\n",
    "    data_table.enable_dataframe_formatter()\n",
    "else:\n",
    "    print(\"Using local Google Cloud SDK credentials.\")\n",
    "\n",
    "client = bigquery.Client(project=project_id)\n",
    "print(f\"BigQuery client initialized for project: {client.project}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Display Database Schema (Optional)\n",
    "\n",
    "**üìä Understanding the MIMIC-III Structure:**\n",
    "\n",
    "This section queries the database metadata to show you all available tables and their columns. This is extremely helpful for:\n",
    "\n",
    "- **Understanding data organization:** See how clinical data is structured\n",
    "- **Planning feature extraction:** Identify which tables contain the data you need\n",
    "- **Learning the schema:** Understand relationships between different data types\n",
    "\n",
    "**Key Tables You'll See:**\n",
    "- **`patients`:** Basic demographics (age, gender, date of birth/death)\n",
    "- **`admissions`:** Hospital admission details (admit/discharge times, diagnoses)\n",
    "- **`icustays`:** ICU-specific information (ICU admit/discharge, length of stay)  \n",
    "- **`chartevents`:** Vital signs and monitoring data (heart rate, blood pressure, etc.)\n",
    "- **`labevents`:** Laboratory test results (blood work, chemistry panels)\n",
    "- **`prescriptions`:** Medication orders and administration\n",
    "- **`microbiologyevents`:** Culture results and antibiotic sensitivity testing\n",
    "\n",
    "**üí° Pro Tip:** Keep this schema reference handy when writing feature extraction queries later in the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pickh\\pythonProject\\MLH\\.venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MIMIC-III Clinical Dataset Schema ---\n",
      "\n",
      "-- Table: admissions --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ADMITTIME (DATETIME)\n",
      "    - DISCHTIME (DATETIME)\n",
      "    - DEATHTIME (DATETIME)\n",
      "    - ADMISSION_TYPE (STRING)\n",
      "    - ADMISSION_LOCATION (STRING)\n",
      "    - DISCHARGE_LOCATION (STRING)\n",
      "    - INSURANCE (STRING)\n",
      "    - LANGUAGE (STRING)\n",
      "    - RELIGION (STRING)\n",
      "    - MARITAL_STATUS (STRING)\n",
      "    - ETHNICITY (STRING)\n",
      "    - EDREGTIME (DATETIME)\n",
      "    - EDOUTTIME (DATETIME)\n",
      "    - DIAGNOSIS (STRING)\n",
      "    - HOSPITAL_EXPIRE_FLAG (INT64)\n",
      "    - HAS_CHARTEVENTS_DATA (INT64)\n",
      "\n",
      "-- Table: callout --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - SUBMIT_WARDID (INT64)\n",
      "    - SUBMIT_CAREUNIT (STRING)\n",
      "    - CURR_WARDID (INT64)\n",
      "    - CURR_CAREUNIT (STRING)\n",
      "    - CALLOUT_WARDID (INT64)\n",
      "    - CALLOUT_SERVICE (STRING)\n",
      "    - REQUEST_TELE (INT64)\n",
      "    - REQUEST_RESP (INT64)\n",
      "    - REQUEST_CDIFF (INT64)\n",
      "    - REQUEST_MRSA (INT64)\n",
      "    - REQUEST_VRE (INT64)\n",
      "    - CALLOUT_STATUS (STRING)\n",
      "    - CALLOUT_OUTCOME (STRING)\n",
      "    - DISCHARGE_WARDID (INT64)\n",
      "    - ACKNOWLEDGE_STATUS (STRING)\n",
      "    - CREATETIME (DATETIME)\n",
      "    - UPDATETIME (DATETIME)\n",
      "    - ACKNOWLEDGETIME (DATETIME)\n",
      "    - OUTCOMETIME (DATETIME)\n",
      "    - FIRSTRESERVATIONTIME (DATETIME)\n",
      "    - CURRENTRESERVATIONTIME (DATETIME)\n",
      "\n",
      "-- Table: caregivers --\n",
      "    - ROW_ID (INT64)\n",
      "    - CGID (INT64)\n",
      "    - LABEL (STRING)\n",
      "    - DESCRIPTION (STRING)\n",
      "\n",
      "-- Table: chartevents --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ICUSTAY_ID (INT64)\n",
      "    - ITEMID (INT64)\n",
      "    - CHARTTIME (DATETIME)\n",
      "    - STORETIME (DATETIME)\n",
      "    - CGID (INT64)\n",
      "    - VALUE (STRING)\n",
      "    - VALUENUM (FLOAT64)\n",
      "    - VALUEUOM (STRING)\n",
      "    - WARNING (INT64)\n",
      "    - ERROR (INT64)\n",
      "    - RESULTSTATUS (STRING)\n",
      "    - STOPPED (STRING)\n",
      "\n",
      "-- Table: cptevents --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - COSTCENTER (STRING)\n",
      "    - CHARTDATE (DATETIME)\n",
      "    - CPT_CD (STRING)\n",
      "    - CPT_NUMBER (INT64)\n",
      "    - CPT_SUFFIX (BOOL)\n",
      "    - TICKET_ID_SEQ (INT64)\n",
      "    - SECTIONHEADER (STRING)\n",
      "    - SUBSECTIONHEADER (STRING)\n",
      "    - DESCRIPTION (STRING)\n",
      "\n",
      "-- Table: d_cpt --\n",
      "    - ROW_ID (INT64)\n",
      "    - CATEGORY (INT64)\n",
      "    - SECTIONRANGE (STRING)\n",
      "    - SECTIONHEADER (STRING)\n",
      "    - SUBSECTIONRANGE (STRING)\n",
      "    - SUBSECTIONHEADER (STRING)\n",
      "    - CODESUFFIX (BOOL)\n",
      "    - MINCODEINSUBSECTION (INT64)\n",
      "    - MAXCODEINSUBSECTION (INT64)\n",
      "\n",
      "-- Table: d_icd_diagnoses --\n",
      "    - ROW_ID (INT64)\n",
      "    - ICD9_CODE (STRING)\n",
      "    - SHORT_TITLE (STRING)\n",
      "    - LONG_TITLE (STRING)\n",
      "\n",
      "-- Table: d_icd_procedures --\n",
      "    - row_id (INT64)\n",
      "    - icd9_code (STRING)\n",
      "    - short_title (STRING)\n",
      "    - long_title (STRING)\n",
      "\n",
      "-- Table: d_items --\n",
      "    - ROW_ID (INT64)\n",
      "    - ITEMID (INT64)\n",
      "    - LABEL (STRING)\n",
      "    - ABBREVIATION (STRING)\n",
      "    - DBSOURCE (STRING)\n",
      "    - LINKSTO (STRING)\n",
      "    - CATEGORY (STRING)\n",
      "    - UNITNAME (STRING)\n",
      "    - PARAM_TYPE (STRING)\n",
      "    - CONCEPTID (STRING)\n",
      "\n",
      "-- Table: d_labitems --\n",
      "    - ROW_ID (INT64)\n",
      "    - ITEMID (INT64)\n",
      "    - LABEL (STRING)\n",
      "    - FLUID (STRING)\n",
      "    - CATEGORY (STRING)\n",
      "    - LOINC_CODE (STRING)\n",
      "\n",
      "-- Table: datetimeevents --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ICUSTAY_ID (INT64)\n",
      "    - ITEMID (INT64)\n",
      "    - CHARTTIME (DATETIME)\n",
      "    - STORETIME (DATETIME)\n",
      "    - CGID (INT64)\n",
      "    - VALUE (DATETIME)\n",
      "    - VALUEUOM (STRING)\n",
      "    - WARNING (INT64)\n",
      "    - ERROR (INT64)\n",
      "    - RESULTSTATUS (STRING)\n",
      "    - STOPPED (STRING)\n",
      "\n",
      "-- Table: diagnoses_icd --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - SEQ_NUM (INT64)\n",
      "    - ICD9_CODE (STRING)\n",
      "\n",
      "-- Table: drgcodes --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - DRG_TYPE (STRING)\n",
      "    - DRG_CODE (STRING)\n",
      "    - DESCRIPTION (STRING)\n",
      "    - DRG_SEVERITY (INT64)\n",
      "    - DRG_MORTALITY (INT64)\n",
      "\n",
      "-- Table: icustays --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ICUSTAY_ID (INT64)\n",
      "    - DBSOURCE (STRING)\n",
      "    - FIRST_CAREUNIT (STRING)\n",
      "    - LAST_CAREUNIT (STRING)\n",
      "    - FIRST_WARDID (INT64)\n",
      "    - LAST_WARDID (INT64)\n",
      "    - INTIME (DATETIME)\n",
      "    - OUTTIME (DATETIME)\n",
      "    - LOS (FLOAT64)\n",
      "\n",
      "-- Table: inputevents_cv --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ICUSTAY_ID (INT64)\n",
      "    - CHARTTIME (DATETIME)\n",
      "    - ITEMID (INT64)\n",
      "    - AMOUNT (FLOAT64)\n",
      "    - AMOUNTUOM (STRING)\n",
      "    - RATE (FLOAT64)\n",
      "    - RATEUOM (STRING)\n",
      "    - STORETIME (DATETIME)\n",
      "    - CGID (INT64)\n",
      "    - ORDERID (INT64)\n",
      "    - LINKORDERID (INT64)\n",
      "    - STOPPED (STRING)\n",
      "    - NEWBOTTLE (INT64)\n",
      "    - ORIGINALAMOUNT (FLOAT64)\n",
      "    - ORIGINALAMOUNTUOM (STRING)\n",
      "    - ORIGINALROUTE (STRING)\n",
      "    - ORIGINALRATE (FLOAT64)\n",
      "    - ORIGINALRATEUOM (STRING)\n",
      "    - ORIGINALSITE (STRING)\n",
      "\n",
      "-- Table: inputevents_mv --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ICUSTAY_ID (INT64)\n",
      "    - STARTTIME (DATETIME)\n",
      "    - ENDTIME (DATETIME)\n",
      "    - ITEMID (INT64)\n",
      "    - AMOUNT (FLOAT64)\n",
      "    - AMOUNTUOM (STRING)\n",
      "    - RATE (FLOAT64)\n",
      "    - RATEUOM (STRING)\n",
      "    - STORETIME (DATETIME)\n",
      "    - CGID (INT64)\n",
      "    - ORDERID (INT64)\n",
      "    - LINKORDERID (INT64)\n",
      "    - ORDERCATEGORYNAME (STRING)\n",
      "    - SECONDARYORDERCATEGORYNAME (STRING)\n",
      "    - ORDERCOMPONENTTYPEDESCRIPTION (STRING)\n",
      "    - ORDERCATEGORYDESCRIPTION (STRING)\n",
      "    - PATIENTWEIGHT (FLOAT64)\n",
      "    - TOTALAMOUNT (FLOAT64)\n",
      "    - TOTALAMOUNTUOM (STRING)\n",
      "    - ISOPENBAG (INT64)\n",
      "    - CONTINUEINNEXTDEPT (INT64)\n",
      "    - CANCELREASON (INT64)\n",
      "    - STATUSDESCRIPTION (STRING)\n",
      "    - COMMENTS_EDITEDBY (STRING)\n",
      "    - COMMENTS_CANCELEDBY (STRING)\n",
      "    - COMMENTS_DATE (DATETIME)\n",
      "    - ORIGINALAMOUNT (FLOAT64)\n",
      "    - ORIGINALRATE (FLOAT64)\n",
      "\n",
      "-- Table: labevents --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ITEMID (INT64)\n",
      "    - CHARTTIME (DATETIME)\n",
      "    - VALUE (STRING)\n",
      "    - VALUENUM (FLOAT64)\n",
      "    - VALUEUOM (STRING)\n",
      "    - FLAG (STRING)\n",
      "\n",
      "-- Table: microbiologyevents --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - CHARTDATE (DATETIME)\n",
      "    - CHARTTIME (DATETIME)\n",
      "    - SPEC_ITEMID (INT64)\n",
      "    - SPEC_TYPE_DESC (STRING)\n",
      "    - ORG_ITEMID (INT64)\n",
      "    - ORG_NAME (STRING)\n",
      "    - ISOLATE_NUM (INT64)\n",
      "    - AB_ITEMID (INT64)\n",
      "    - AB_NAME (STRING)\n",
      "    - DILUTION_TEXT (STRING)\n",
      "    - DILUTION_COMPARISON (STRING)\n",
      "    - DILUTION_VALUE (INT64)\n",
      "    - INTERPRETATION (STRING)\n",
      "\n",
      "-- Table: outputevents --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ICUSTAY_ID (INT64)\n",
      "    - CHARTTIME (DATETIME)\n",
      "    - ITEMID (INT64)\n",
      "    - VALUE (FLOAT64)\n",
      "    - VALUEUOM (STRING)\n",
      "    - STORETIME (DATETIME)\n",
      "    - CGID (INT64)\n",
      "    - STOPPED (STRING)\n",
      "    - NEWBOTTLE (STRING)\n",
      "    - ISERROR (STRING)\n",
      "\n",
      "-- Table: patients --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - GENDER (STRING)\n",
      "    - DOB (DATETIME)\n",
      "    - DOD (DATETIME)\n",
      "    - DOD_HOSP (DATETIME)\n",
      "    - DOD_SSN (DATETIME)\n",
      "    - EXPIRE_FLAG (INT64)\n",
      "\n",
      "-- Table: prescriptions --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ICUSTAY_ID (INT64)\n",
      "    - STARTDATE (DATETIME)\n",
      "    - ENDDATE (DATETIME)\n",
      "    - DRUG_TYPE (STRING)\n",
      "    - DRUG (STRING)\n",
      "    - DRUG_NAME_POE (STRING)\n",
      "    - DRUG_NAME_GENERIC (STRING)\n",
      "    - FORMULARY_DRUG_CD (STRING)\n",
      "    - GSN (STRING)\n",
      "    - NDC (INT64)\n",
      "    - PROD_STRENGTH (STRING)\n",
      "    - DOSE_VAL_RX (STRING)\n",
      "    - DOSE_UNIT_RX (STRING)\n",
      "    - FORM_VAL_DISP (STRING)\n",
      "    - FORM_UNIT_DISP (STRING)\n",
      "    - ROUTE (STRING)\n",
      "\n",
      "-- Table: procedureevents_mv --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ICUSTAY_ID (INT64)\n",
      "    - STARTTIME (DATETIME)\n",
      "    - ENDTIME (DATETIME)\n",
      "    - ITEMID (INT64)\n",
      "    - VALUE (FLOAT64)\n",
      "    - VALUEUOM (STRING)\n",
      "    - LOCATION (STRING)\n",
      "    - LOCATIONCATEGORY (STRING)\n",
      "    - STORETIME (DATETIME)\n",
      "    - CGID (INT64)\n",
      "    - ORDERID (INT64)\n",
      "    - LINKORDERID (INT64)\n",
      "    - ORDERCATEGORYNAME (STRING)\n",
      "    - SECONDARYORDERCATEGORYNAME (STRING)\n",
      "    - ORDERCATEGORYDESCRIPTION (STRING)\n",
      "    - ISOPENBAG (INT64)\n",
      "    - CONTINUEINNEXTDEPT (INT64)\n",
      "    - CANCELREASON (INT64)\n",
      "    - STATUSDESCRIPTION (STRING)\n",
      "    - COMMENTS_EDITEDBY (STRING)\n",
      "    - COMMENTS_CANCELEDBY (STRING)\n",
      "    - COMMENTS_DATE (DATETIME)\n",
      "\n",
      "-- Table: procedures_icd --\n",
      "    - row_id (INT64)\n",
      "    - subject_id (INT64)\n",
      "    - hadm_id (INT64)\n",
      "    - seq_num (INT64)\n",
      "    - icd9_code (STRING)\n",
      "\n",
      "-- Table: services --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - TRANSFERTIME (DATETIME)\n",
      "    - PREV_SERVICE (STRING)\n",
      "    - CURR_SERVICE (STRING)\n",
      "\n",
      "-- Table: transfers --\n",
      "    - ROW_ID (INT64)\n",
      "    - SUBJECT_ID (INT64)\n",
      "    - HADM_ID (INT64)\n",
      "    - ICUSTAY_ID (INT64)\n",
      "    - DBSOURCE (STRING)\n",
      "    - EVENTTYPE (STRING)\n",
      "    - PREV_CAREUNIT (STRING)\n",
      "    - CURR_CAREUNIT (STRING)\n",
      "    - PREV_WARDID (INT64)\n",
      "    - CURR_WARDID (INT64)\n",
      "    - INTIME (DATETIME)\n",
      "    - OUTTIME (DATETIME)\n",
      "    - LOS (FLOAT64)\n",
      "\n",
      "--- End of Schema ---\n"
     ]
    }
   ],
   "source": [
    "# The project ID for the public MIMIC-III dataset\n",
    "schema_project_id = \"physionet-data\"\n",
    "schema_dataset_id = \"mimiciii_clinical\"\n",
    "\n",
    "# Query the INFORMATION_SCHEMA to get table and column details\n",
    "schema_query = f\"\"\"\n",
    "    SELECT\n",
    "        table_name,\n",
    "        column_name,\n",
    "        data_type\n",
    "    FROM `{schema_project_id}.{schema_dataset_id}.INFORMATION_SCHEMA.COLUMNS`\n",
    "    ORDER BY\n",
    "        table_name,\n",
    "        ordinal_position;\n",
    "\"\"\"\n",
    "\n",
    "# Run the query\n",
    "schema_df = client.query(schema_query).to_dataframe()\n",
    "\n",
    "# Process and print the schema\n",
    "if schema_df.empty:\n",
    "    print(\"Could not retrieve schema. The dataset might be empty or inaccessible.\")\n",
    "else:\n",
    "    print(\"--- MIMIC-III Clinical Dataset Schema ---\")\n",
    "    current_table = \"\"\n",
    "    for index, row in schema_df.iterrows():\n",
    "        if row['table_name'] != current_table:\n",
    "            current_table = row['table_name']\n",
    "            print(f\"\\n-- Table: {current_table} --\")\n",
    "        print(f\"    - {row['column_name']} ({row['data_type']})\")\n",
    "    print(\"\\n--- End of Schema ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Framework\n",
    "\n",
    "This section outlines the development of our prediction models, adhering to the project guidelines. We will implement a full pipeline, from data extraction to model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and Configuration\n",
    "\n",
    "**‚è±Ô∏è Temporal Design Parameters:**\n",
    "\n",
    "These constants define the critical timing constraints for our prediction task:\n",
    "\n",
    "```\n",
    "|<--- DATA_COLLECTION_HOURS --->|<-- GAP -->|<--- PREDICTION WINDOW --->|\n",
    "|           48 hours            |  6 hours  |     Monitor outcomes      |\n",
    "|                               |           |                           |\n",
    "Admission -----------------> Feature -----> Prediction -----------------> Discharge\n",
    "          Extract vitals,    Cutoff        Point\n",
    "          labs, meds, etc.                 \n",
    "```\n",
    "\n",
    "**Why These Specific Values?**\n",
    "\n",
    "- **48-hour collection window:** Captures the critical initial period when most clinical decisions are made\n",
    "- **6-hour prediction gap:** Ensures we're truly predicting future outcomes, not just describing current state\n",
    "- **54-hour minimum stay:** Ensures all patients have enough data for both feature extraction and outcome definition\n",
    "\n",
    "**Clinical Rationale:**\n",
    "- Early intervention is crucial in critical care\n",
    "- Most ICU deaths occur within the first few days  \n",
    "- Hospital systems need time to act on predictions (hence the gap)\n",
    "- Prolonged stay threshold (7 days) represents significant resource utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Project constants based on the guidelines\n",
    "DATA_COLLECTION_HOURS = 48\n",
    "PREDICTION_GAP_HOURS = 6\n",
    "MIN_HOSPITALIZATION_HOURS = DATA_COLLECTION_HOURS + PREDICTION_GAP_HOURS  # 54 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Extraction\n",
    "\n",
    "**üéØ Goal:** Extract and preprocess the required data modalities for our cohort.\n",
    "\n",
    "**üìä Required Data Modalities (per project guidelines):**\n",
    "- ‚úÖ **Demographic features** (age, gender, ethnicity, insurance)\n",
    "- ‚úÖ **Vital signs** (heart rate, blood pressure, temperature, respiratory rate, SpO2)\n",
    "- ‚úÖ **Laboratory test results** (basic metabolic panel, complete blood count, liver function)\n",
    "- ‚úÖ **Medications** (antibiotics, vasopressors, sedatives, insulin)\n",
    "- ‚úÖ **Microbiology events** (culture results, organism identification, antibiotic sensitivity)\n",
    "\n",
    "**üè• Patient Selection Criteria:**\n",
    "- **First hospital admission only** (to avoid repeated admissions bias)\n",
    "- **Minimum 54 hours hospitalization** (48h feature extraction + 6h prediction gap)\n",
    "- **Has chartevents data** (ensures ICU-level monitoring was available)\n",
    "- **From provided initial cohort CSV** (ensures reproducible patient selection)\n",
    "\n",
    "**‚è±Ô∏è Temporal Constraints:**\n",
    "All features will be extracted from the **first 48 hours** of admission to ensure:\n",
    "- No future information leakage\n",
    "- Clinically actionable timing (early in hospital course)\n",
    "- Sufficient data for robust feature engineering\n",
    "\n",
    "**üîÑ Processing Pipeline:**\n",
    "1. Load initial cohort subject IDs from CSV\n",
    "2. Extract first admission demographics for each patient  \n",
    "3. Filter by minimum stay requirements\n",
    "4. Prepare for target definition and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Initial Cohort\n",
    "\n",
    "**üìÑ About the Initial Cohort CSV:**\n",
    "\n",
    "The `initial_cohort.csv` file contains ~32,500 subject IDs that have been pre-selected for this project. This ensures:\n",
    "\n",
    "- **Reproducible results:** Everyone works with the same patient population\n",
    "- **Quality control:** Patients have been pre-screened for data completeness\n",
    "- **Project scope:** Manageable dataset size for analysis and modeling\n",
    "\n",
    "**üîç What happens here:**\n",
    "1. Load the CSV file containing subject IDs\n",
    "2. Convert to a list for use in BigQuery parameterized queries\n",
    "3. Error handling if the file is missing or corrupted\n",
    "4. Display cohort size for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 32513 subject IDs from initial_cohort.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22392, 2847, 12056, 25600, 73125, 13429, 5023, 47109, 50434, 2920]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the initial cohort from the provided CSV file\n",
    "try:\n",
    "    cohort_subject_ids_df = pd.read_csv('../data/initial_cohort.csv')\n",
    "    subject_ids = cohort_subject_ids_df['subject_id'].tolist()\n",
    "    print(f\"Successfully loaded {len(subject_ids)} subject IDs from initial_cohort.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/initial_cohort.csv' not found.\")\n",
    "    print(\"Please ensure the file exists and the path is correct.\")\n",
    "    subject_ids = []  # Set to empty list to prevent query errors\n",
    "\n",
    "\n",
    "subject_ids[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Extract Initial Cohort Demographics\n",
    "\n",
    "**üè• SQL Query Breakdown:**\n",
    "\n",
    "This complex query performs several critical steps:\n",
    "\n",
    "**Step 1: `admissions_for_cohort`**\n",
    "- Joins `patients` and `admissions` tables\n",
    "- Filters to only our cohort patients (from CSV)\n",
    "- Ensures admissions have chartevents data (ICU-level monitoring)\n",
    "- Extracts key demographics and admission details\n",
    "\n",
    "**Step 2: `first_admissions`** \n",
    "- Uses `ROW_NUMBER()` to rank admissions by time for each patient\n",
    "- Ensures we only get the **first admission** per patient\n",
    "- Critical for avoiding bias from repeated admissions\n",
    "\n",
    "**Step 3: `final_cohort`**\n",
    "- Calculates length of stay in hours using `DATETIME_DIFF`\n",
    "- Filters for minimum 54-hour stays (our temporal requirement)\n",
    "- Produces final analysis-ready cohort\n",
    "\n",
    "**üéØ Key Filtering Criteria:**\n",
    "- `has_chartevents_data = 1`: Ensures ICU-level monitoring\n",
    "- `rn = 1`: First admission only  \n",
    "- `length_of_stay_hours >= 54`: Meets temporal requirements\n",
    "\n",
    "**üìä Expected Output:**\n",
    "- ~28,500 patients (some filtered out due to stay length)\n",
    "- Columns: demographics, admission/discharge times, length of stay\n",
    "- Ready for target definition and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28552 patients from the CSV who meet the criteria.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>insurance</th>\n",
       "      <th>rn</th>\n",
       "      <th>length_of_stay_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421</td>\n",
       "      <td>174459</td>\n",
       "      <td>2157-04-13 02:08:00</td>\n",
       "      <td>2157-04-22 18:50:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>M</td>\n",
       "      <td>2105-07-15</td>\n",
       "      <td>HISPANIC/LATINO - DOMINICAN</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3886</td>\n",
       "      <td>165159</td>\n",
       "      <td>2125-01-09 17:16:00</td>\n",
       "      <td>2125-01-20 12:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>F</td>\n",
       "      <td>2058-08-10</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4776</td>\n",
       "      <td>112029</td>\n",
       "      <td>2122-12-15 20:47:00</td>\n",
       "      <td>2122-12-18 12:20:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>M</td>\n",
       "      <td>2082-05-06</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16940</td>\n",
       "      <td>193636</td>\n",
       "      <td>2120-01-28 16:15:00</td>\n",
       "      <td>2120-03-29 12:20:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>F</td>\n",
       "      <td>2120-01-28</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17343</td>\n",
       "      <td>123590</td>\n",
       "      <td>2155-09-07 06:45:00</td>\n",
       "      <td>2155-09-11 10:40:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>M</td>\n",
       "      <td>2155-09-07</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id           admittime           dischtime deathtime  \\\n",
       "0         421   174459 2157-04-13 02:08:00 2157-04-22 18:50:00       NaT   \n",
       "1        3886   165159 2125-01-09 17:16:00 2125-01-20 12:00:00       NaT   \n",
       "2        4776   112029 2122-12-15 20:47:00 2122-12-18 12:20:00       NaT   \n",
       "3       16940   193636 2120-01-28 16:15:00 2120-03-29 12:20:00       NaT   \n",
       "4       17343   123590 2155-09-07 06:45:00 2155-09-11 10:40:00       NaT   \n",
       "\n",
       "  gender        dob                    ethnicity   insurance  rn  \\\n",
       "0      M 2105-07-15  HISPANIC/LATINO - DOMINICAN  Government   1   \n",
       "1      F 2058-08-10                        WHITE  Government   1   \n",
       "2      M 2082-05-06       BLACK/AFRICAN AMERICAN  Government   1   \n",
       "3      F 2120-01-28                        OTHER  Government   1   \n",
       "4      M 2155-09-07       BLACK/AFRICAN AMERICAN  Government   1   \n",
       "\n",
       "   length_of_stay_hours  \n",
       "0                   232  \n",
       "1                   259  \n",
       "2                    64  \n",
       "3                  1460  \n",
       "4                   100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_cohort_query = '''\n",
    "-- This query extracts the first admission for a specified list of patients,\n",
    "-- ensuring their hospital stay meets a minimum duration.\n",
    "\n",
    "-- Step 1: Filter admissions to only include the patients specified in the cohort\n",
    "WITH admissions_for_cohort AS (\n",
    "    SELECT\n",
    "        p.subject_id,\n",
    "        a.hadm_id,\n",
    "        a.admittime,\n",
    "        a.dischtime,\n",
    "        a.deathtime,\n",
    "        p.gender,\n",
    "        p.dob,\n",
    "        a.ethnicity,\n",
    "        a.insurance\n",
    "    FROM `physionet-data.mimiciii_clinical.patients` p\n",
    "    INNER JOIN `physionet-data.mimiciii_clinical.admissions` a ON p.subject_id = a.subject_id\n",
    "    WHERE\n",
    "        -- Only include patients from our initial cohort list\n",
    "        p.subject_id IN UNNEST(@subject_ids)\n",
    "        -- And ensure the admission has associated chart events\n",
    "        AND a.has_chartevents_data = 1\n",
    "),\n",
    "\n",
    "-- Step 2: Identify the first admission for each patient\n",
    "first_admissions AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        -- Assign a row number to each admission, ordered by time\n",
    "        ROW_NUMBER() OVER(PARTITION BY subject_id ORDER BY admittime) as rn\n",
    "    FROM admissions_for_cohort\n",
    "),\n",
    "\n",
    "-- Step 3: Calculate length of stay and filter by the minimum required duration\n",
    "final_cohort AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        -- Calculate the duration of the hospital stay in hours\n",
    "        DATETIME_DIFF(dischtime, admittime, HOUR) as length_of_stay_hours\n",
    "    FROM first_admissions\n",
    "    WHERE\n",
    "        -- We only want the very first admission\n",
    "        rn = 1\n",
    ")\n",
    "\n",
    "-- Final Selection: Select all columns from the processed and filtered cohort\n",
    "SELECT *\n",
    "FROM final_cohort\n",
    "WHERE\n",
    "    -- Ensure the hospital stay is long enough for our analysis\n",
    "    length_of_stay_hours >= @min_hospitalization_hours\n",
    "'''\n",
    "\n",
    "query_params = [\n",
    "    bigquery.ArrayQueryParameter(\"subject_ids\", \"INT64\", subject_ids),\n",
    "    bigquery.ScalarQueryParameter(\"min_hospitalization_hours\", \"INT64\", MIN_HOSPITALIZATION_HOURS),\n",
    "]\n",
    "\n",
    "job_config = bigquery.QueryJobConfig(\n",
    "    query_parameters=query_params\n",
    ")\n",
    "\n",
    "# Only run the query if subject_ids were loaded successfully\n",
    "if subject_ids:\n",
    "    initial_cohort_df = client.query(initial_cohort_query, job_config=job_config).to_dataframe()\n",
    "    print(f\"Found {len(initial_cohort_df)} patients from the CSV who meet the criteria.\")\n",
    "    display(initial_cohort_df.head())\n",
    "else:\n",
    "    print(\"Query skipped because no subject IDs were loaded.\")\n",
    "    initial_cohort_df = pd.DataFrame() # Create an empty dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Readmission Detection Query\n",
    "\n",
    "**Step 1: `all_admissions_for_cohort_patients`**\n",
    "- Query ALL admissions for our cohort patients (not just the cohort admission)\n",
    "- This gives us the complete admission history for each patient\n",
    "\n",
    "**Step 2: `cohort_with_next_admission`**  \n",
    "- For each cohort admission (first admission), find the next admission\n",
    "- Use `LEFT JOIN` with condition `a.admittime > c.dischtime` \n",
    "- Use `MIN()` to get the earliest subsequent admission\n",
    "- Results in `next_admittime` for readmission detection\n",
    "\n",
    "**üéØ Key Insights:**\n",
    "- Many patients have only one admission (no readmission)\n",
    "- Some patients have multiple readmissions (we want the first one)\n",
    "- The 30-day window is applied later in the target definition function\n",
    "\n",
    "**üõ°Ô∏è Data Integrity:**\n",
    "- Uses parameterized queries to prevent SQL injection\n",
    "- Handles temporary table creation and cleanup\n",
    "- Robust error handling for BigQuery operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pickh\\pythonProject\\MLH\\.venv\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n",
      "c:\\Users\\pickh\\pythonProject\\MLH\\.venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added readmission data for 28552 patients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>insurance</th>\n",
       "      <th>rn</th>\n",
       "      <th>length_of_stay_hours</th>\n",
       "      <th>next_admittime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421</td>\n",
       "      <td>174459</td>\n",
       "      <td>2157-04-13 02:08:00</td>\n",
       "      <td>2157-04-22 18:50:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>M</td>\n",
       "      <td>2105-07-15</td>\n",
       "      <td>HISPANIC/LATINO - DOMINICAN</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>232</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3886</td>\n",
       "      <td>165159</td>\n",
       "      <td>2125-01-09 17:16:00</td>\n",
       "      <td>2125-01-20 12:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>F</td>\n",
       "      <td>2058-08-10</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>259</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4776</td>\n",
       "      <td>112029</td>\n",
       "      <td>2122-12-15 20:47:00</td>\n",
       "      <td>2122-12-18 12:20:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>M</td>\n",
       "      <td>2082-05-06</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16940</td>\n",
       "      <td>193636</td>\n",
       "      <td>2120-01-28 16:15:00</td>\n",
       "      <td>2120-03-29 12:20:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>F</td>\n",
       "      <td>2120-01-28</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>1460</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17343</td>\n",
       "      <td>123590</td>\n",
       "      <td>2155-09-07 06:45:00</td>\n",
       "      <td>2155-09-11 10:40:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>M</td>\n",
       "      <td>2155-09-07</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id           admittime           dischtime deathtime  \\\n",
       "0         421   174459 2157-04-13 02:08:00 2157-04-22 18:50:00       NaT   \n",
       "1        3886   165159 2125-01-09 17:16:00 2125-01-20 12:00:00       NaT   \n",
       "2        4776   112029 2122-12-15 20:47:00 2122-12-18 12:20:00       NaT   \n",
       "3       16940   193636 2120-01-28 16:15:00 2120-03-29 12:20:00       NaT   \n",
       "4       17343   123590 2155-09-07 06:45:00 2155-09-11 10:40:00       NaT   \n",
       "\n",
       "  gender        dob                    ethnicity   insurance  rn  \\\n",
       "0      M 2105-07-15  HISPANIC/LATINO - DOMINICAN  Government   1   \n",
       "1      F 2058-08-10                        WHITE  Government   1   \n",
       "2      M 2082-05-06       BLACK/AFRICAN AMERICAN  Government   1   \n",
       "3      F 2120-01-28                        OTHER  Government   1   \n",
       "4      M 2155-09-07       BLACK/AFRICAN AMERICAN  Government   1   \n",
       "\n",
       "   length_of_stay_hours next_admittime  \n",
       "0                   232            NaT  \n",
       "1                   259            NaT  \n",
       "2                    64            NaT  \n",
       "3                  1460            NaT  \n",
       "4                   100            NaT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query to find subsequent admissions for readmission detection\n",
    "readmission_query = \"\"\"\n",
    "-- Get all admissions for patients in our cohort to detect readmissions\n",
    "WITH all_admissions_for_cohort_patients AS (\n",
    "    SELECT \n",
    "        a.subject_id,\n",
    "        a.hadm_id,\n",
    "        DATETIME(a.admittime) as admittime  -- Ensure DATETIME type\n",
    "    FROM `physionet-data.mimiciii_clinical.admissions` a\n",
    "    WHERE a.subject_id IN UNNEST(@subject_ids)\n",
    "),\n",
    "cohort_with_next_admission AS (\n",
    "    SELECT \n",
    "        c.subject_id,\n",
    "        c.hadm_id,\n",
    "        DATETIME(c.dischtime) as dischtime,  -- Ensure DATETIME type\n",
    "        MIN(a.admittime) as next_admittime\n",
    "    FROM initial_cohort_df c\n",
    "    LEFT JOIN all_admissions_for_cohort_patients a \n",
    "        ON c.subject_id = a.subject_id \n",
    "        AND a.admittime > DATETIME(c.dischtime)  -- Cast both sides to DATETIME\n",
    "    GROUP BY c.subject_id, c.hadm_id, c.dischtime\n",
    ")\n",
    "SELECT \n",
    "    subject_id,\n",
    "    hadm_id,\n",
    "    next_admittime\n",
    "FROM cohort_with_next_admission\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query only if we don't already have readmission data\n",
    "if not initial_cohort_df.empty and subject_ids:\n",
    "    # Create a temporary table from the initial_cohort_df to use in the query\n",
    "    client.create_dataset('temp_dataset', exists_ok=True)\n",
    "    table_ref = client.dataset('temp_dataset').table('initial_cohort_df')\n",
    "    job = client.load_table_from_dataframe(\n",
    "        initial_cohort_df[['subject_id', 'hadm_id', 'dischtime']], \n",
    "        table_ref\n",
    "    )\n",
    "    job.result()  # Wait for the table to be created\n",
    "    \n",
    "    # Set up query parameters\n",
    "    query_params = [bigquery.ArrayQueryParameter(\"subject_ids\", \"INT64\", subject_ids)]\n",
    "    job_config = bigquery.QueryJobConfig(query_parameters=query_params)\n",
    "    \n",
    "    # Run the readmission query\n",
    "    readmission_df = client.query(\n",
    "        readmission_query.replace('initial_cohort_df', '`temp_dataset.initial_cohort_df`'),\n",
    "        job_config=job_config\n",
    "    ).to_dataframe()\n",
    "    \n",
    "    # Merge the readmission time back into our main cohort dataframe\n",
    "    initial_cohort_df = pd.merge(\n",
    "        initial_cohort_df, \n",
    "        readmission_df[['subject_id', 'hadm_id', 'next_admittime']], \n",
    "        on=['subject_id', 'hadm_id'], \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Clean up the temp table\n",
    "    client.delete_table(table_ref, not_found_ok=True)\n",
    "    print(f\"Added readmission data for {len(initial_cohort_df)} patients\")\n",
    "    display(initial_cohort_df.head())\n",
    "else:\n",
    "    print(\"Skipped readmission query - no cohort data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 1.4 Feature Extraction\n\n**üéØ Goal:** Extract the required clinical data modalities from MIMIC-III tables.\n\n**üìä Data Modalities to Extract:**\n- **Vital signs** (heart rate, blood pressure, temperature, respiratory rate, SpO2)\n- **Laboratory test results** (basic metabolic panel, complete blood count, liver function)\n- **Medications** (antibiotics, vasopressors, sedatives, insulin)\n- **Microbiology events** (culture results, organism identification, antibiotic sensitivity)\n\n**‚è±Ô∏è Temporal Constraint:** All features extracted from **first 48 hours** of admission only."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### 1.4.1 Vital Signs Extraction\n\n**ü´Ä Extracting Vital Signs from Chartevents:**\n\nCritical vital signs for ICU prediction models."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Vital signs ITEMID mapping for MIMIC-III\nvital_signs_items = {\n    'heart_rate': [211, 220045],  # Heart Rate\n    'sbp': [51, 442, 455, 6701, 220179, 220050],  # Systolic BP\n    'dbp': [8368, 8440, 8441, 8555, 220180, 220051],  # Diastolic BP\n    'mbp': [52, 6702, 443, 220052, 220181, 225312],  # Mean BP\n    'resp_rate': [615, 618, 220210, 224690],  # Respiratory Rate\n    'temperature': [223762, 676, 223761, 678],  # Temperature\n    'spo2': [646, 220277],  # SpO2\n    'glucose': [807, 811, 1529, 3745, 3744, 225664, 220621, 226537]  # Glucose\n}\n\n# Extract vital signs within 48 hours of admission\nvital_signs_query = \"\"\"\nWITH cohort_admissions AS (\n    SELECT subject_id, hadm_id, DATETIME(admittime) as admittime\n    FROM `temp_dataset.initial_cohort_df`\n),\nvital_signs_raw AS (\n    SELECT \n        c.subject_id,\n        c.hadm_id,\n        ce.itemid,\n        DATETIME(ce.charttime) as charttime,\n        ce.valuenum,\n        CASE \n            WHEN ce.itemid IN UNNEST(@heart_rate_items) THEN 'heart_rate'\n            WHEN ce.itemid IN UNNEST(@sbp_items) THEN 'sbp'\n            WHEN ce.itemid IN UNNEST(@dbp_items) THEN 'dbp'\n            WHEN ce.itemid IN UNNEST(@mbp_items) THEN 'mbp'\n            WHEN ce.itemid IN UNNEST(@resp_rate_items) THEN 'resp_rate'\n            WHEN ce.itemid IN UNNEST(@temperature_items) THEN 'temperature'\n            WHEN ce.itemid IN UNNEST(@spo2_items) THEN 'spo2'\n            WHEN ce.itemid IN UNNEST(@glucose_items) THEN 'glucose'\n        END AS vital_type\n    FROM cohort_admissions c\n    INNER JOIN `physionet-data.mimiciii_clinical.chartevents` ce\n        ON c.subject_id = ce.subject_id \n        AND c.hadm_id = ce.hadm_id\n    WHERE \n        ce.itemid IN UNNEST(@all_vital_items)\n        AND DATETIME(ce.charttime) >= c.admittime\n        AND DATETIME(ce.charttime) <= DATETIME_ADD(c.admittime, INTERVAL @data_collection_hours HOUR)\n        AND ce.valuenum IS NOT NULL\n        AND ce.error != 1\n)\nSELECT \n    subject_id,\n    hadm_id,\n    vital_type,\n    COUNT(*) as measurement_count,\n    AVG(valuenum) as avg_value,\n    MIN(valuenum) as min_value,\n    MAX(valuenum) as max_value,\n    STDDEV(valuenum) as std_value\nFROM vital_signs_raw\nGROUP BY subject_id, hadm_id, vital_type\n\"\"\"\n\nif not initial_cohort_df.empty:\n    # Create temporary table\n    client.create_dataset('temp_dataset', exists_ok=True)\n    table_ref = client.dataset('temp_dataset').table('initial_cohort_df')\n    job = client.load_table_from_dataframe(\n        initial_cohort_df[['subject_id', 'hadm_id', 'admittime']], \n        table_ref\n    )\n    job.result()\n    \n    # Prepare all vital sign item IDs\n    all_vital_items = []\n    for items in vital_signs_items.values():\n        all_vital_items.extend(items)\n    \n    # Set up query parameters\n    query_params = [\n        bigquery.ArrayQueryParameter(\"heart_rate_items\", \"INT64\", vital_signs_items['heart_rate']),\n        bigquery.ArrayQueryParameter(\"sbp_items\", \"INT64\", vital_signs_items['sbp']),\n        bigquery.ArrayQueryParameter(\"dbp_items\", \"INT64\", vital_signs_items['dbp']),\n        bigquery.ArrayQueryParameter(\"mbp_items\", \"INT64\", vital_signs_items['mbp']),\n        bigquery.ArrayQueryParameter(\"resp_rate_items\", \"INT64\", vital_signs_items['resp_rate']),\n        bigquery.ArrayQueryParameter(\"temperature_items\", \"INT64\", vital_signs_items['temperature']),\n        bigquery.ArrayQueryParameter(\"spo2_items\", \"INT64\", vital_signs_items['spo2']),\n        bigquery.ArrayQueryParameter(\"glucose_items\", \"INT64\", vital_signs_items['glucose']),\n        bigquery.ArrayQueryParameter(\"all_vital_items\", \"INT64\", all_vital_items),\n        bigquery.ScalarQueryParameter(\"data_collection_hours\", \"INT64\", DATA_COLLECTION_HOURS),\n    ]\n    \n    job_config = bigquery.QueryJobConfig(query_parameters=query_params)\n    \n    # Execute vital signs query\n    vital_signs_df = client.query(vital_signs_query, job_config=job_config).to_dataframe()\n    \n    print(f\"Extracted vital signs for {vital_signs_df['subject_id'].nunique()} patients\")\n    print(f\"Vital signs extracted: {vital_signs_df['vital_type'].unique()}\")\n    display(vital_signs_df.head(10))\nelse:\n    print(\"No cohort data available for vital signs extraction\")\n    vital_signs_df = pd.DataFrame()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### 1.4.2 Laboratory Results Extraction\n\n**üß™ Extracting Lab Results from Labevents (ONLY):**\n\n**‚ö†Ô∏è Important:** Using ONLY labevents table as per project instructions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Laboratory test ITEMID mapping for MIMIC-III (labevents only)\nlab_items = {\n    # Basic Metabolic Panel\n    'sodium': [50983],\n    'potassium': [50971], \n    'chloride': [50902],\n    'co2': [50882],\n    'bun': [51006],\n    'creatinine': [50912],\n    'glucose': [50931],\n    \n    # Complete Blood Count\n    'hemoglobin': [51222],\n    'hematocrit': [51221], \n    'wbc': [51301],\n    'platelet': [51265],\n    \n    # Liver Function\n    'bilirubin_total': [50885],\n    'alt': [50861],\n    'ast': [50878],\n    'alkaline_phosphatase': [50863],\n    \n    # Additional important labs\n    'lactate': [50813],\n    'ph': [50820],\n    'albumin': [50862]\n}\n\n# Extract lab results within 48 hours of admission\nlab_results_query = \"\"\"\nWITH cohort_admissions AS (\n    SELECT subject_id, hadm_id, admittime\n    FROM `temp_dataset.initial_cohort_df`\n),\nlab_results_raw AS (\n    SELECT \n        c.subject_id,\n        c.hadm_id,\n        le.itemid,\n        le.charttime,\n        le.valuenum,\n        CASE \n            WHEN le.itemid IN UNNEST(@sodium_items) THEN 'sodium'\n            WHEN le.itemid IN UNNEST(@potassium_items) THEN 'potassium'\n            WHEN le.itemid IN UNNEST(@chloride_items) THEN 'chloride'\n            WHEN le.itemid IN UNNEST(@co2_items) THEN 'co2'\n            WHEN le.itemid IN UNNEST(@bun_items) THEN 'bun'\n            WHEN le.itemid IN UNNEST(@creatinine_items) THEN 'creatinine'\n            WHEN le.itemid IN UNNEST(@glucose_items) THEN 'glucose_lab'\n            WHEN le.itemid IN UNNEST(@hemoglobin_items) THEN 'hemoglobin'\n            WHEN le.itemid IN UNNEST(@hematocrit_items) THEN 'hematocrit'\n            WHEN le.itemid IN UNNEST(@wbc_items) THEN 'wbc'\n            WHEN le.itemid IN UNNEST(@platelet_items) THEN 'platelet'\n            WHEN le.itemid IN UNNEST(@bilirubin_items) THEN 'bilirubin_total'\n            WHEN le.itemid IN UNNEST(@alt_items) THEN 'alt'\n            WHEN le.itemid IN UNNEST(@ast_items) THEN 'ast'\n            WHEN le.itemid IN UNNEST(@alkphos_items) THEN 'alkaline_phosphatase'\n            WHEN le.itemid IN UNNEST(@lactate_items) THEN 'lactate'\n            WHEN le.itemid IN UNNEST(@ph_items) THEN 'ph'\n            WHEN le.itemid IN UNNEST(@albumin_items) THEN 'albumin'\n        END AS lab_type\n    FROM cohort_admissions c\n    INNER JOIN `physionet-data.mimiciii_clinical.labevents` le\n        ON c.subject_id = le.subject_id \n        AND c.hadm_id = le.hadm_id\n    WHERE \n        le.itemid IN UNNEST(@all_lab_items)\n        AND le.charttime >= c.admittime\n        AND le.charttime <= DATETIME_ADD(c.admittime, INTERVAL @data_collection_hours HOUR)\n        AND le.valuenum IS NOT NULL\n)\nSELECT \n    subject_id,\n    hadm_id,\n    lab_type,\n    COUNT(*) as measurement_count,\n    AVG(valuenum) as avg_value,\n    MIN(valuenum) as min_value,\n    MAX(valuenum) as max_value,\n    STDDEV(valuenum) as std_value\nFROM lab_results_raw\nGROUP BY subject_id, hadm_id, lab_type\n\"\"\"\n\nif not initial_cohort_df.empty:\n    # Prepare all lab item IDs\n    all_lab_items = []\n    for items in lab_items.values():\n        all_lab_items.extend(items)\n    \n    # Set up query parameters\n    query_params = [\n        bigquery.ArrayQueryParameter(\"sodium_items\", \"INT64\", lab_items['sodium']),\n        bigquery.ArrayQueryParameter(\"potassium_items\", \"INT64\", lab_items['potassium']),\n        bigquery.ArrayQueryParameter(\"chloride_items\", \"INT64\", lab_items['chloride']),\n        bigquery.ArrayQueryParameter(\"co2_items\", \"INT64\", lab_items['co2']),\n        bigquery.ArrayQueryParameter(\"bun_items\", \"INT64\", lab_items['bun']),\n        bigquery.ArrayQueryParameter(\"creatinine_items\", \"INT64\", lab_items['creatinine']),\n        bigquery.ArrayQueryParameter(\"glucose_items\", \"INT64\", lab_items['glucose']),\n        bigquery.ArrayQueryParameter(\"hemoglobin_items\", \"INT64\", lab_items['hemoglobin']),\n        bigquery.ArrayQueryParameter(\"hematocrit_items\", \"INT64\", lab_items['hematocrit']),\n        bigquery.ArrayQueryParameter(\"wbc_items\", \"INT64\", lab_items['wbc']),\n        bigquery.ArrayQueryParameter(\"platelet_items\", \"INT64\", lab_items['platelet']),\n        bigquery.ArrayQueryParameter(\"bilirubin_items\", \"INT64\", lab_items['bilirubin_total']),\n        bigquery.ArrayQueryParameter(\"alt_items\", \"INT64\", lab_items['alt']),\n        bigquery.ArrayQueryParameter(\"ast_items\", \"INT64\", lab_items['ast']),\n        bigquery.ArrayQueryParameter(\"alkphos_items\", \"INT64\", lab_items['alkaline_phosphatase']),\n        bigquery.ArrayQueryParameter(\"lactate_items\", \"INT64\", lab_items['lactate']),\n        bigquery.ArrayQueryParameter(\"ph_items\", \"INT64\", lab_items['ph']),\n        bigquery.ArrayQueryParameter(\"albumin_items\", \"INT64\", lab_items['albumin']),\n        bigquery.ArrayQueryParameter(\"all_lab_items\", \"INT64\", all_lab_items),\n        bigquery.ScalarQueryParameter(\"data_collection_hours\", \"INT64\", DATA_COLLECTION_HOURS),\n    ]\n    \n    job_config = bigquery.QueryJobConfig(query_parameters=query_params)\n    \n    # Execute lab results query\n    lab_results_df = client.query(lab_results_query, job_config=job_config).to_dataframe()\n    \n    print(f\"Extracted lab results for {lab_results_df['subject_id'].nunique()} patients\")\n    print(f\"Lab tests extracted: {lab_results_df['lab_type'].unique()}\")\n    display(lab_results_df.head(10))\nelse:\n    print(\"No cohort data available for lab results extraction\")\n    lab_results_df = pd.DataFrame()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### 1.4.3 Medications Extraction\n\n**üíä Extracting Medications from Prescriptions:**\n\nFocus on clinically important medication categories."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Medication categories of clinical interest\nmedication_keywords = {\n    'antibiotics': ['antibiotic', 'penicillin', 'cephalexin', 'amoxicillin', 'ciprofloxacin', \n                   'vancomycin', 'gentamicin', 'ceftriaxone', 'azithromycin', 'clindamycin'],\n    'vasopressors': ['norepinephrine', 'epinephrine', 'dopamine', 'dobutamine', 'vasopressin', \n                    'phenylephrine', 'milrinone'],\n    'sedatives': ['propofol', 'midazolam', 'lorazepam', 'fentanyl', 'morphine', 'dexmedetomidine'],\n    'insulin': ['insulin', 'humulin', 'novolog', 'lantus', 'humalog'],\n    'anticoagulants': ['heparin', 'warfarin', 'enoxaparin', 'fondaparinux'],\n    'diuretics': ['furosemide', 'lasix', 'hydrochlorothiazide', 'spironolactone'],\n    'beta_blockers': ['metoprolol', 'propranolol', 'atenolol', 'carvedilol'],\n    'ace_inhibitors': ['lisinopril', 'enalapril', 'captopril', 'ramipril']\n}\n\n# Extract medications within 48 hours of admission\nmedications_query = \"\"\"\nWITH cohort_admissions AS (\n    SELECT subject_id, hadm_id, admittime\n    FROM `temp_dataset.initial_cohort_df`\n),\nmedications_raw AS (\n    SELECT \n        c.subject_id,\n        c.hadm_id,\n        p.drug,\n        p.drug_name_generic,\n        p.startdate,\n        CASE \n            WHEN REGEXP_CONTAINS(LOWER(COALESCE(p.drug, p.drug_name_generic, '')), r'antibiotic|penicillin|cephalexin|amoxicillin|ciprofloxacin|vancomycin|gentamicin|ceftriaxone|azithromycin|clindamycin') THEN 'antibiotics'\n            WHEN REGEXP_CONTAINS(LOWER(COALESCE(p.drug, p.drug_name_generic, '')), r'norepinephrine|epinephrine|dopamine|dobutamine|vasopressin|phenylephrine|milrinone') THEN 'vasopressors'\n            WHEN REGEXP_CONTAINS(LOWER(COALESCE(p.drug, p.drug_name_generic, '')), r'propofol|midazolam|lorazepam|fentanyl|morphine|dexmedetomidine') THEN 'sedatives'\n            WHEN REGEXP_CONTAINS(LOWER(COALESCE(p.drug, p.drug_name_generic, '')), r'insulin|humulin|novolog|lantus|humalog') THEN 'insulin'\n            WHEN REGEXP_CONTAINS(LOWER(COALESCE(p.drug, p.drug_name_generic, '')), r'heparin|warfarin|enoxaparin|fondaparinux') THEN 'anticoagulants'\n            WHEN REGEXP_CONTAINS(LOWER(COALESCE(p.drug, p.drug_name_generic, '')), r'furosemide|lasix|hydrochlorothiazide|spironolactone') THEN 'diuretics'\n            WHEN REGEXP_CONTAINS(LOWER(COALESCE(p.drug, p.drug_name_generic, '')), r'metoprolol|propranolol|atenolol|carvedilol') THEN 'beta_blockers'\n            WHEN REGEXP_CONTAINS(LOWER(COALESCE(p.drug, p.drug_name_generic, '')), r'lisinopril|enalapril|captopril|ramipril') THEN 'ace_inhibitors'\n        END AS medication_category\n    FROM cohort_admissions c\n    INNER JOIN `physionet-data.mimiciii_clinical.prescriptions` p\n        ON c.subject_id = p.subject_id \n        AND c.hadm_id = p.hadm_id\n    WHERE \n        p.startdate >= DATE(c.admittime)\n        AND p.startdate <= DATE_ADD(DATE(c.admittime), INTERVAL @data_collection_days DAY)\n        AND (p.drug IS NOT NULL OR p.drug_name_generic IS NOT NULL)\n)\nSELECT \n    subject_id,\n    hadm_id,\n    medication_category,\n    COUNT(*) as prescription_count,\n    COUNT(DISTINCT drug) as unique_drugs\nFROM medications_raw\nWHERE medication_category IS NOT NULL\nGROUP BY subject_id, hadm_id, medication_category\n\"\"\"\n\nif not initial_cohort_df.empty:\n    # Set up query parameters\n    query_params = [\n        bigquery.ScalarQueryParameter(\"data_collection_days\", \"INT64\", 2),  # 48 hours = 2 days\n    ]\n    \n    job_config = bigquery.QueryJobConfig(query_parameters=query_params)\n    \n    # Execute medications query\n    medications_df = client.query(medications_query, job_config=job_config).to_dataframe()\n    \n    print(f\"Extracted medications for {medications_df['subject_id'].nunique()} patients\")\n    print(f\"Medication categories extracted: {medications_df['medication_category'].unique()}\")\n    display(medications_df.head(10))\nelse:\n    print(\"No cohort data available for medications extraction\")\n    medications_df = pd.DataFrame()"
  },
  {
   "cell_type": "markdown",
   "source": "#### 1.4.4 Microbiology Events Extraction\n\n**ü¶† Extracting Microbiology from Microbiologyevents:**\n\nCulture results and organism identification within 48 hours.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Extract microbiology events within 48 hours of admission\nmicrobiology_query = \"\"\"\nWITH cohort_admissions AS (\n    SELECT subject_id, hadm_id, admittime\n    FROM `temp_dataset.initial_cohort_df`\n),\nmicrobiology_raw AS (\n    SELECT \n        c.subject_id,\n        c.hadm_id,\n        me.chartdate,\n        me.spec_type_desc,\n        me.org_name,\n        me.interpretation,\n        CASE \n            WHEN me.spec_type_desc IS NOT NULL THEN 'culture_ordered'\n            ELSE NULL\n        END AS culture_type,\n        CASE \n            WHEN me.org_name IS NOT NULL AND me.org_name != '' THEN 'organism_found'\n            ELSE 'no_growth'\n        END AS culture_result,\n        CASE \n            WHEN LOWER(me.interpretation) LIKE '%sensitive%' OR LOWER(me.interpretation) LIKE '%susceptible%' THEN 'sensitive'\n            WHEN LOWER(me.interpretation) LIKE '%resistant%' THEN 'resistant'\n            WHEN LOWER(me.interpretation) LIKE '%intermediate%' THEN 'intermediate'\n            ELSE 'unknown'\n        END AS antibiotic_sensitivity\n    FROM cohort_admissions c\n    INNER JOIN `physionet-data.mimiciii_clinical.microbiologyevents` me\n        ON c.subject_id = me.subject_id \n        AND c.hadm_id = me.hadm_id\n    WHERE \n        me.chartdate >= DATE(c.admittime)\n        AND me.chartdate <= DATE_ADD(DATE(c.admittime), INTERVAL @data_collection_days DAY)\n)\nSELECT \n    subject_id,\n    hadm_id,\n    'cultures_ordered' as micro_type,\n    COUNT(*) as count_value\nFROM microbiology_raw\nGROUP BY subject_id, hadm_id\n\nUNION ALL\n\nSELECT \n    subject_id,\n    hadm_id,\n    culture_result as micro_type,\n    COUNT(*) as count_value\nFROM microbiology_raw\nGROUP BY subject_id, hadm_id, culture_result\n\nUNION ALL\n\nSELECT \n    subject_id,\n    hadm_id,\n    CONCAT('sensitivity_', antibiotic_sensitivity) as micro_type,\n    COUNT(*) as count_value\nFROM microbiology_raw\nWHERE antibiotic_sensitivity != 'unknown'\nGROUP BY subject_id, hadm_id, antibiotic_sensitivity\n\"\"\"\n\nif not initial_cohort_df.empty:\n    # Set up query parameters\n    query_params = [\n        bigquery.ScalarQueryParameter(\"data_collection_days\", \"INT64\", 2),  # 48 hours = 2 days\n    ]\n    \n    job_config = bigquery.QueryJobConfig(query_parameters=query_params)\n    \n    # Execute microbiology query\n    microbiology_df = client.query(microbiology_query, job_config=job_config).to_dataframe()\n    \n    print(f\"Extracted microbiology data for {microbiology_df['subject_id'].nunique()} patients\")\n    print(f\"Microbiology types extracted: {microbiology_df['micro_type'].unique()}\")\n    display(microbiology_df.head(10))\nelse:\n    print(\"No cohort data available for microbiology extraction\")\n    microbiology_df = pd.DataFrame()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 1.5 Exploratory Data Analysis\n\n**üéØ Goal:** Understand the characteristics of our extracted patient cohort and clinical features.\n\nThis section analyzes the basic demographic characteristics and data quality of our ICU cohort to inform target definition and modeling decisions.\n\n**üìä What We'll Explore:**\n- Demographics (age, gender, ethnicity, insurance)\n- Length of stay patterns \n- Missing data assessment\n- Data quality validation\n\n**‚ö†Ô∏è Important Note:** This EDA happens AFTER feature extraction to understand our complete dataset."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#### 1.5.1 Demographic Analysis\n\n**üë• Understanding Our Patient Population:**\n\nThis analysis examines the basic demographic characteristics of our ICU cohort after feature extraction."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Partition\n",
    "\n",
    "**üéØ Goal:** Split the data into training, validation, and test sets.\n",
    "\n",
    "To prevent data leakage, we will split our cohort by `subject_id` before any feature engineering or preprocessing that looks across patients. A standard 60/20/20 split will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#### 1.5.2 Hospital Stay Analysis\n\n**üè• Length of Stay Patterns:**\n\nUnderstanding length of stay patterns before defining the prolonged stay target."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}